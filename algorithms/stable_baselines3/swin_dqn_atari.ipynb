{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-11T14:41:52.303266Z",
     "end_time": "2023-04-11T14:41:52.344018Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "from gymnasium import spaces\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.preprocessing import is_image_space\n",
    "from stable_baselines3.dqn.policies import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "\n",
    "from transformers import SwinModel, SwinConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "SwinModel(\n  (embeddings): SwinEmbeddings(\n    (patch_embeddings): SwinPatchEmbeddings(\n      (projection): Conv2d(4, 96, kernel_size=(3, 3), stride=(3, 3))\n    )\n    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.0, inplace=False)\n  )\n  (encoder): SwinEncoder(\n    (layers): ModuleList(\n      (0): SwinStage(\n        (blocks): ModuleList(\n          (0-1): 2 x SwinLayer(\n            (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n            (attention): SwinAttention(\n              (self): SwinSelfAttention(\n                (query): Linear(in_features=96, out_features=96, bias=True)\n                (key): Linear(in_features=96, out_features=96, bias=True)\n                (value): Linear(in_features=96, out_features=96, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n              (output): SwinSelfOutput(\n                (dense): Linear(in_features=96, out_features=96, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (drop_path): SwinDropPath(p=0.1)\n            (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n            (intermediate): SwinIntermediate(\n              (dense): Linear(in_features=96, out_features=384, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): SwinOutput(\n              (dense): Linear(in_features=384, out_features=96, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (downsample): SwinPatchMerging(\n          (reduction): Linear(in_features=384, out_features=192, bias=False)\n          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (1): SwinStage(\n        (blocks): ModuleList(\n          (0-2): 3 x SwinLayer(\n            (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n            (attention): SwinAttention(\n              (self): SwinSelfAttention(\n                (query): Linear(in_features=192, out_features=192, bias=True)\n                (key): Linear(in_features=192, out_features=192, bias=True)\n                (value): Linear(in_features=192, out_features=192, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n              (output): SwinSelfOutput(\n                (dense): Linear(in_features=192, out_features=192, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (drop_path): SwinDropPath(p=0.1)\n            (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n            (intermediate): SwinIntermediate(\n              (dense): Linear(in_features=192, out_features=768, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): SwinOutput(\n              (dense): Linear(in_features=768, out_features=192, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (downsample): SwinPatchMerging(\n          (reduction): Linear(in_features=768, out_features=384, bias=False)\n          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (2): SwinStage(\n        (blocks): ModuleList(\n          (0-1): 2 x SwinLayer(\n            (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n            (attention): SwinAttention(\n              (self): SwinSelfAttention(\n                (query): Linear(in_features=384, out_features=384, bias=True)\n                (key): Linear(in_features=384, out_features=384, bias=True)\n                (value): Linear(in_features=384, out_features=384, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n              (output): SwinSelfOutput(\n                (dense): Linear(in_features=384, out_features=384, bias=True)\n                (dropout): Dropout(p=0.0, inplace=False)\n              )\n            )\n            (drop_path): SwinDropPath(p=0.1)\n            (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n            (intermediate): SwinIntermediate(\n              (dense): Linear(in_features=384, out_features=1536, bias=True)\n              (intermediate_act_fn): GELUActivation()\n            )\n            (output): SwinOutput(\n              (dense): Linear(in_features=1536, out_features=384, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n      )\n    )\n  )\n  (layernorm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n  (pooler): AdaptiveAvgPool1d(output_size=1)\n)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SWIN_CONFIG = SwinConfig(\n",
    "    image_size=84,\n",
    "    patch_size=3,\n",
    "    num_channels=4,\n",
    "    embed_dim=96,\n",
    "    depths=[2, 3, 2],\n",
    "    num_heads=[3, 3, 6],\n",
    "    window_size=7,\n",
    "    mlp_ratio=4.0,\n",
    "    drop_path_rate=0.1,\n",
    ")\n",
    "swin = SwinModel(SWIN_CONFIG)\n",
    "swin"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T14:41:52.710444Z",
     "end_time": "2023-04-11T14:41:52.817344Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class SwinDQN(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: spaces.Box, features_dim: int = 384, normalized_image: bool = False,):\n",
    "        assert isinstance(observation_space, spaces.Box), (\n",
    "            \"SwinDQN must be used with a gym.spaces.Box \",\n",
    "            f\"observation space, not {observation_space}\",\n",
    "        )\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        # We assume CxHxW images (channels first)\n",
    "        # Re-ordering will be done by pre-preprocessing or wrapper\n",
    "        assert is_image_space(observation_space, check_channels=False, normalized_image=normalized_image), (\n",
    "            \"You should use SwinDQN \"\n",
    "            f\"only with images not with {observation_space}\\n\"\n",
    "            \"(you are probably using `CnnPolicy` instead of `MlpPolicy` or `MultiInputPolicy`)\\n\"\n",
    "            \"If you are using `VecNormalize` or already normalized channel-first images \"\n",
    "            \"you should pass `normalize_images=False`: \\n\"\n",
    "            \"https://stable-baselines3.readthedocs.io/en/master/guide/custom_env.html\"\n",
    "        )\n",
    "\n",
    "        num_input_channels = observation_space.shape[0]\n",
    "        config = SwinConfig(\n",
    "            image_size=84,\n",
    "            patch_size=3,\n",
    "            num_channels=num_input_channels,\n",
    "            embed_dim=96,\n",
    "            depths=[2, 3, 2],\n",
    "            num_heads=[3, 3, 6],\n",
    "            window_size=7,\n",
    "            mlp_ratio=4.0,\n",
    "            drop_path_rate=0.1,\n",
    "        )\n",
    "\n",
    "        self.swin = SwinModel(config)\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        return self.swin(observations).pooler_output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T14:41:53.455128Z",
     "end_time": "2023-04-11T14:41:53.471596Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "env = make_atari_env(\"ALE/Pong-v5\", n_envs=1, seed=42, env_kwargs={\"full_action_space\": False, \"frameskip\": 1})\n",
    "# Frame-stacking with 4 frames\n",
    "env = VecFrameStack(env, n_stack=4)\n",
    "\n",
    "NAME = \"Swin_DQN_Pong-v5\"\n",
    "\n",
    "current_datetime_str = datetime.now().strftime(\"%d-%m-%Y_%H:%M:%S\")\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=500_000,\n",
    "    save_path=f\"runs/checkpoints/{NAME}_{current_datetime_str}\",\n",
    "    name_prefix=NAME,\n",
    "    save_replay_buffer=True,\n",
    ")\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=SwinDQN,\n",
    "    net_arch=[],\n",
    ")\n",
    "\n",
    "model = DQN(\"CnnPolicy\",\n",
    "            env,\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            verbose=1,\n",
    "            tensorboard_log=\"runs/logs/\",\n",
    "            batch_size=32,\n",
    "            buffer_size=10_000,\n",
    "            exploration_final_eps=0.01,\n",
    "            exploration_fraction=0.1,\n",
    "            gradient_steps=1,\n",
    "            learning_rate=0.0001,\n",
    "            learning_starts=100_000,\n",
    "            optimize_memory_usage=True,\n",
    "            replay_buffer_kwargs={\"handle_timeout_termination\": False},\n",
    "            target_update_interval=1000,\n",
    "            train_freq=4,)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T14:41:54.906932Z",
     "end_time": "2023-04-11T14:41:56.537085Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.learn(10_000_000, tb_log_name=f\"{NAME}_{current_datetime_str}\", callback=checkpoint_callback)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
