{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-11T14:35:55.495045Z",
     "end_time": "2023-04-11T14:35:55.538903Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "env = make_atari_env(\"ALE/Pong-v5\", n_envs=1, seed=42, env_kwargs={\"full_action_space\": False, \"frameskip\": 1})\n",
    "# Frame-stacking with 4 frames\n",
    "env = VecFrameStack(env, n_stack=4)\n",
    "\n",
    "current_datetime_str = datetime.now().strftime(\"%d-%m-%Y_%H:%M:%S\")\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=500_000,\n",
    "    save_path=f\"runs/checkpoints/CNN_DQN_Pong-v5_{current_datetime_str}\",\n",
    "    name_prefix=\"CNN_DQN_Pong-v5\",\n",
    "    save_replay_buffer=True,\n",
    ")\n",
    "\n",
    "model = DQN(\"CnnPolicy\",\n",
    "            env,\n",
    "            verbose=1,\n",
    "            tensorboard_log=\"runs/logs/\",\n",
    "            batch_size=32,\n",
    "            buffer_size=10_000,\n",
    "            exploration_final_eps=0.01,\n",
    "            exploration_fraction=0.1,\n",
    "            gradient_steps=1,\n",
    "            learning_rate=0.0001,\n",
    "            learning_starts=100_000,\n",
    "            optimize_memory_usage=True,\n",
    "            replay_buffer_kwargs={\"handle_timeout_termination\": False},\n",
    "            target_update_interval=1000,\n",
    "            train_freq=4,)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T14:37:12.690298Z",
     "end_time": "2023-04-11T14:37:12.858777Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to runs/logs/CNN_DQN_Pong-v5_11-04-2023_14:37:12_1\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.63e+03 |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.996    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 1080     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 3601     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.62e+03 |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.993    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 1070     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 7199     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.63e+03 |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.989    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 1014     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 10826    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.58e+03 |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.986    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 1035     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 14241    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.65e+03 |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.982    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 1053     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 18128    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.62e+03 |\n",
      "|    ep_rew_mean      | -20.7    |\n",
      "|    exploration_rate | 0.979    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 951      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 21570    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.61e+03 |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.975    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 969      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 25136    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.62e+03 |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.971    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 984      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 28794    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.61e+03 |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.968    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 919      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 32307    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.62e+03 |\n",
      "|    ep_rew_mean      | -20.6    |\n",
      "|    exploration_rate | 0.964    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 935      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 36021    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 3.63e+03 |\n",
      "|    ep_rew_mean      | -20.5    |\n",
      "|    exploration_rate | 0.961    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 946      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 39734    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m10_000_000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCNN_DQN_Pong-v5_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mcurrent_datetime_str\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheckpoint_callback\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/stable-baselines3/lib/python3.8/site-packages/stable_baselines3/dqn/dqn.py:269\u001B[0m, in \u001B[0;36mDQN.learn\u001B[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlearn\u001B[39m(\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;28mself\u001B[39m: SelfDQN,\n\u001B[1;32m    262\u001B[0m     total_timesteps: \u001B[38;5;28mint\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    267\u001B[0m     progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    268\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m SelfDQN:\n\u001B[0;32m--> 269\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtotal_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtb_log_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtb_log_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset_num_timesteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/stable-baselines3/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py:311\u001B[0m, in \u001B[0;36mOffPolicyAlgorithm.learn\u001B[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001B[0m\n\u001B[1;32m    308\u001B[0m callback\u001B[38;5;241m.\u001B[39mon_training_start(\u001B[38;5;28mlocals\u001B[39m(), \u001B[38;5;28mglobals\u001B[39m())\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_timesteps \u001B[38;5;241m<\u001B[39m total_timesteps:\n\u001B[0;32m--> 311\u001B[0m     rollout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect_rollouts\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_freq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43maction_noise\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maction_noise\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlearning_starts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearning_starts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreplay_buffer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreplay_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m rollout\u001B[38;5;241m.\u001B[39mcontinue_training \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[1;32m    322\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/stable-baselines3/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py:558\u001B[0m, in \u001B[0;36mOffPolicyAlgorithm.collect_rollouts\u001B[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001B[0m\n\u001B[1;32m    555\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_info_buffer(infos, dones)\n\u001B[1;32m    557\u001B[0m \u001B[38;5;66;03m# Store data in replay buffer (normalized action and unnormalized observation)\u001B[39;00m\n\u001B[0;32m--> 558\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_store_transition\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreplay_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer_actions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_obs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrewards\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdones\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minfos\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    560\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_current_progress_remaining(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_timesteps, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_total_timesteps)\n\u001B[1;32m    562\u001B[0m \u001B[38;5;66;03m# For DQN, check if the target network should be updated\u001B[39;00m\n\u001B[1;32m    563\u001B[0m \u001B[38;5;66;03m# and update the exploration schedule\u001B[39;00m\n\u001B[1;32m    564\u001B[0m \u001B[38;5;66;03m# For SAC/TD3, the update is dones as the same time as the gradient update\u001B[39;00m\n\u001B[1;32m    565\u001B[0m \u001B[38;5;66;03m# see https://github.com/hill-a/stable-baselines/issues/900\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/stable-baselines3/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py:471\u001B[0m, in \u001B[0;36mOffPolicyAlgorithm._store_transition\u001B[0;34m(self, replay_buffer, buffer_action, new_obs, reward, dones, infos)\u001B[0m\n\u001B[1;32m    468\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vec_normalize_env \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    469\u001B[0m                 next_obs[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vec_normalize_env\u001B[38;5;241m.\u001B[39munnormalize_obs(next_obs[i, :])\n\u001B[0;32m--> 471\u001B[0m \u001B[43mreplay_buffer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    472\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_last_original_obs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    473\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnext_obs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    474\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbuffer_action\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    475\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreward_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    476\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdones\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    477\u001B[0m \u001B[43m    \u001B[49m\u001B[43minfos\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    478\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    480\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_last_obs \u001B[38;5;241m=\u001B[39m new_obs\n\u001B[1;32m    481\u001B[0m \u001B[38;5;66;03m# Save the unnormalized observation\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/stable-baselines3/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:253\u001B[0m, in \u001B[0;36mReplayBuffer.add\u001B[0;34m(self, obs, next_obs, action, reward, done, infos)\u001B[0m\n\u001B[1;32m    250\u001B[0m action \u001B[38;5;241m=\u001B[39m action\u001B[38;5;241m.\u001B[39mreshape((\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_envs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maction_dim))\n\u001B[1;32m    252\u001B[0m \u001B[38;5;66;03m# Copy to avoid modification by reference\u001B[39;00m\n\u001B[0;32m--> 253\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobservations[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpos] \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimize_memory_usage:\n\u001B[1;32m    256\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobservations[(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpos \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuffer_size] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(next_obs)\u001B[38;5;241m.\u001B[39mcopy()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(10_000_000, tb_log_name=f\"CNN_DQN_Pong-v5_{current_datetime_str}\", callback=checkpoint_callback)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
